{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f0bb0708",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geocoder\n",
    "import toml\n",
    "import tweepy\n",
    "import json\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb161a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install TwitterSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8e7540c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_busca = ['copa do mundo', 'copa 2022', '#copadomundo','#Qatar2022', 'albumdacopa', '#FIFAWorldCup', '#FIFA', '#WorldCup', 'Football', 'Soccer', '#Futbol', 'copa do mundo', 'Qatar 2022', 'Copa do mundo Qatar', 'World Cup Qatar', '#FIFAWorldCup2022', 'WorldCupFinal', 'WorldCup2022', '#FIFA2022', '#albumdacopa', 'figurinhas copa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c46ee30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# abrir o arquivo com as credenciais de acesso\n",
    "with open('config.toml') as config:\n",
    "  # ler o arquivo e salvar as chaves nas variáveis\n",
    "  config = toml.loads(config.read())\n",
    "  APP_NAME = config['APP_NAME']\n",
    "  API_KEY = config['API_KEY']\n",
    "  API_KEY_SECRET = config['API_KEY_SECRET']\n",
    "  ACCESS_TOKEN = config['ACCESS_TOKEN']\n",
    "  ACCESS_TOKEN_SECRET = config['ACCESS_TOKEN_SECRET']\n",
    "  BEARER_TOKEN = config['BEARER_TOKEN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a54498d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from TwitterSearch import *\n",
    "\n",
    "try:\n",
    "    \n",
    "    ts = TwitterSearch(  # Objeto TwitterSearch object\n",
    "        consumer_key = API_KEY,\n",
    "        consumer_secret = API_KEY_SECRET,\n",
    "        access_token = ACCESS_TOKEN,\n",
    "        access_token_secret = ACCESS_TOKEN_SECRET\n",
    "    )\n",
    "    \n",
    "    tso = TwitterSearchOrder() # cria objeto TwitterSearchOrder\n",
    "    tso.set_keywords(lista_busca, or_operator = True)\n",
    "    #tso.set_language('pt')\n",
    "    #tso.set_count(26)\n",
    "    \n",
    "    for tweet in ts.search_tweets_iterable(tso): # ts.search_tweets_iterable(tso) é um metadata\n",
    "        \n",
    "        #print('created_at: ',tweet['created_at'], 'User_id: ', tweet['id_str'], 'Tweet: ', tweet['text'], hashtags, tweet['entities']['hashtags'])\n",
    "        \n",
    "        created_at = tweet['created_at']\n",
    "        user_id = tweet['id_str']\n",
    "        texto = tweet['text']\n",
    "        location = tweet['user']['location']\n",
    "        retweet_count = tweet['retweet_count']\n",
    "        source = tweet['source']\n",
    "        likes = tweet['favorite_count']\n",
    "        \n",
    "        \n",
    "        with open('tweet.json','a+') as output:\n",
    "            \n",
    "            data = {'created_at': created_at,\n",
    "                    'User_id': user_id,\n",
    "                   'tweet': texto,\n",
    "                   'location': location,\n",
    "                   'retweet_count': retweet_count,\n",
    "                   'source': source,\n",
    "                    'likes': likes}\n",
    "            #print(data)\n",
    "            output.write('{}\\n'.format(json.dumps(data)))\n",
    "except TwitterSearchException as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9a4309a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>User_id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>location</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>source</th>\n",
       "      <th>likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-09-26 18:45:26+00:00</td>\n",
       "      <td>1574470215580225536</td>\n",
       "      <td>a única coisa boa seria se eu já  tivesse uma ...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-09-26 18:44:55+00:00</td>\n",
       "      <td>1574470087842504704</td>\n",
       "      <td>RT @ueapaixonei: vc tem 55 dias pra decidir  s...</td>\n",
       "      <td></td>\n",
       "      <td>786</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-09-26 18:44:51+00:00</td>\n",
       "      <td>1574470071120007168</td>\n",
       "      <td>RT @breiller: - Fora da Copa do Mundo pela seg...</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>3171</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-09-26 18:44:47+00:00</td>\n",
       "      <td>1574470052715401216</td>\n",
       "      <td>RT @NeymarJrSite: Nosso craque @neymarjr e seu...</td>\n",
       "      <td>Uberlândia - MG</td>\n",
       "      <td>11</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-09-26 18:44:46+00:00</td>\n",
       "      <td>1574470046973399040</td>\n",
       "      <td>RT @realfutebolnews: Estamos buscando chegar e...</td>\n",
       "      <td></td>\n",
       "      <td>913</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2022-09-26 18:37:05+00:00</td>\n",
       "      <td>1574468115504795648</td>\n",
       "      <td>Quartas de Final da Copa do Mundo \\n\\nBrasil x...</td>\n",
       "      <td>Tatuape, São Paulo</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2022-09-26 18:36:58+00:00</td>\n",
       "      <td>1574468084211093504</td>\n",
       "      <td>Mas uma copa do mundo modo solo 🇧🇷</td>\n",
       "      <td>CPX CGL 🚩🇲🇿,</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2022-09-26 18:36:56+00:00</td>\n",
       "      <td>1574468079295369216</td>\n",
       "      <td>Em pleno 2022, ano de copa do mundo, ano de el...</td>\n",
       "      <td>Tangará da Serra, Brasil</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2022-09-26 18:36:49+00:00</td>\n",
       "      <td>1574468047795998720</td>\n",
       "      <td>RT @breiller: - Fora da Copa do Mundo pela seg...</td>\n",
       "      <td>021</td>\n",
       "      <td>3171</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2022-09-26 18:36:44+00:00</td>\n",
       "      <td>1574468025608278016</td>\n",
       "      <td>RT @ueapaixonei: vc tem 55 dias pra decidir  s...</td>\n",
       "      <td>Anápolis, Brasil</td>\n",
       "      <td>786</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  created_at              User_id  \\\n",
       "0  2022-09-26 18:45:26+00:00  1574470215580225536   \n",
       "1  2022-09-26 18:44:55+00:00  1574470087842504704   \n",
       "2  2022-09-26 18:44:51+00:00  1574470071120007168   \n",
       "3  2022-09-26 18:44:47+00:00  1574470052715401216   \n",
       "4  2022-09-26 18:44:46+00:00  1574470046973399040   \n",
       "..                       ...                  ...   \n",
       "95 2022-09-26 18:37:05+00:00  1574468115504795648   \n",
       "96 2022-09-26 18:36:58+00:00  1574468084211093504   \n",
       "97 2022-09-26 18:36:56+00:00  1574468079295369216   \n",
       "98 2022-09-26 18:36:49+00:00  1574468047795998720   \n",
       "99 2022-09-26 18:36:44+00:00  1574468025608278016   \n",
       "\n",
       "                                                tweet  \\\n",
       "0   a única coisa boa seria se eu já  tivesse uma ...   \n",
       "1   RT @ueapaixonei: vc tem 55 dias pra decidir  s...   \n",
       "2   RT @breiller: - Fora da Copa do Mundo pela seg...   \n",
       "3   RT @NeymarJrSite: Nosso craque @neymarjr e seu...   \n",
       "4   RT @realfutebolnews: Estamos buscando chegar e...   \n",
       "..                                                ...   \n",
       "95  Quartas de Final da Copa do Mundo \\n\\nBrasil x...   \n",
       "96                 Mas uma copa do mundo modo solo 🇧🇷   \n",
       "97  Em pleno 2022, ano de copa do mundo, ano de el...   \n",
       "98  RT @breiller: - Fora da Copa do Mundo pela seg...   \n",
       "99  RT @ueapaixonei: vc tem 55 dias pra decidir  s...   \n",
       "\n",
       "                    location  retweet_count  \\\n",
       "0                                         0   \n",
       "1                                       786   \n",
       "2                     Brazil           3171   \n",
       "3            Uberlândia - MG             11   \n",
       "4                                       913   \n",
       "..                       ...            ...   \n",
       "95        Tatuape, São Paulo              0   \n",
       "96             CPX CGL 🚩🇲🇿,               0   \n",
       "97  Tangará da Serra, Brasil              0   \n",
       "98                       021           3171   \n",
       "99          Anápolis, Brasil            786   \n",
       "\n",
       "                                               source  likes  \n",
       "0   <a href=\"http://twitter.com/download/android\" ...      0  \n",
       "1   <a href=\"http://twitter.com/download/iphone\" r...      0  \n",
       "2   <a href=\"https://mobile.twitter.com\" rel=\"nofo...      0  \n",
       "3   <a href=\"http://twitter.com/download/android\" ...      0  \n",
       "4   <a href=\"http://twitter.com/download/android\" ...      0  \n",
       "..                                                ...    ...  \n",
       "95  <a href=\"http://twitter.com/download/android\" ...      1  \n",
       "96  <a href=\"http://twitter.com/download/android\" ...      0  \n",
       "97  <a href=\"http://twitter.com/download/android\" ...      2  \n",
       "98  <a href=\"http://twitter.com/download/android\" ...      0  \n",
       "99  <a href=\"http://twitter.com/download/iphone\" r...      0  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_json('tweet.json',lines = True)\n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "97ea09c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18596, 7)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8982169b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo os valores duplicados:\n",
    "df.drop_duplicates(['tweet'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d08f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb43905",
   "metadata": {},
   "source": [
    "# NLTK (Natural Language Toolkit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608258e3",
   "metadata": {},
   "source": [
    "#### O NLTK (Natural Language Toolkit) é uma biblioteca que contém pacotes para fazer com que as máquinas entendam a linguagem humana. Abaixo alguns dos pacotes mais importante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c863d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install nltk\n",
    "#nltk.dowload()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74af3de9",
   "metadata": {},
   "source": [
    "# Stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadaf4a6",
   "metadata": {},
   "source": [
    "#### São palavras e termos frequentes porém que não possuem relevância nas sentenças\n",
    "#### Exemplos: as, os, um, uma, com, de, da, para, et..\n",
    "#### O nltk possui uma lista de stopwords em 16 idiomas diferentes. Vamos criar função que remova todas as stopwords em Portuquês."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d51fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para remover Stopwords da nossa base:\n",
    "def RemoveStopWords(instancia):\n",
    "    stopwords = set(nltk.corpus.stopwords('portuguese'))\n",
    "    palavras = [i for i instancia.split() if not i in stopwords]\n",
    "    return (' '.join(palavra))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3363dff1",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280c6872",
   "metadata": {},
   "source": [
    "#### É a técnica de reduzir uma palavra para o seu radical, mesmo que o radical em si não seja válida no idioma. Removendo os sufixos e prefixos de uma palavra\n",
    "- Exemplo: O radical da palavra ilegal é ileg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd869c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando o stemming em nossa base:\n",
    "def Stemming(instancia):\n",
    "    stemmer = nltk.stem.RSLPStemmer()\n",
    "    palavras = []\n",
    "    for w in instancia.split():\n",
    "        palavras.append(stemmer.stem(w))\n",
    "    return (' '.join(palavras))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad8c398",
   "metadata": {},
   "source": [
    "# Remove caracteres indesejados como links e etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63a5fec",
   "metadata": {},
   "source": [
    "#### Remover as pontuações e os links, pois eles não adiciona nenhuma informação extra ao tratar dados de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78b94066",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea9a708b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpeza_dados(instancia):\n",
    "    # remove links, pontos, virgulas, ponto e virgulas dos tweets\n",
    "    instancia = re.sub(r\"https\\S+\", \"\", instancia).lower().replace('.','').replace(';','').replace('-','').replace(':','').replace(')','')\n",
    "    return instancia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c65d515f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "def tweet_to_words(tweet):\n",
    "    \n",
    "    tweet = BeautifulSoup(tweet, 'html.parser').get_text() # Remove HTML Tags\n",
    "    tweet = re.sub(r\"[^a-zA-Zà-úÀ-Ú0-9]\", \"\", tweet.lower()) # Limpa e converte para minusculo\n",
    "    tweet = tweet_tokenizer.tokenize(tweet)\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4905a5d",
   "metadata": {},
   "source": [
    "# Tokenização"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae72bc9",
   "metadata": {},
   "source": [
    "#### É o processo de tokenizar ou dividir uma string ou textos em uma lista de tokens. O tokenizado padrão da nltk, usa o espaço para separar as palavras\n",
    "\n",
    "#### Exemplo: 'Data Science do Zero'\n",
    "\n",
    "#### Vai ficar: ['Data', 'Science', 'do', 'Zero']\n",
    "\n",
    "#### No Twitter é muito comum a utilização de @ e # além dos emoji, se usarmos o tokenizador padrão na nossa base, ele vai dividir as string de forma incorreta, deixando de representar o tweets.\n",
    "\n",
    "#### frase = \"O video do @blogminerando é show! :=) S2 -) =D\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bc296db",
   "metadata": {},
   "outputs": [],
   "source": [
    " frase = \"O video do @blogminerando é show! :=) S2 -) =D\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4615fcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "tweet_tokenizer = TweetTokenizer()\n",
    "tweet_tokenizer.tokenizer.tokenize(frase)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a951ceb",
   "metadata": {},
   "source": [
    "# Tokenizar o Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3360228",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13adc6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_tokenized = [tweet_tokenizer.tokenize(tweet) for tweet in df.tweet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b59ed56",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_tokenized[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec6f026",
   "metadata": {},
   "source": [
    "# Remover os caracteress indesejados e stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39280421",
   "metadata": {},
   "source": [
    "## Remover os caracteress indesejados e stopwords com nltk e re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d9b616",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Preprocessing(instancia):\n",
    "    instancia = re.sub(r\"https\\S+\", \"\", instancia).lower().replace('.','').replace(';','').replace('-','').replace(':','').replace(')','')\n",
    "    stopwords = set(nltk.corpus.stopwords.words('portuguese'))\n",
    "    palavras = [i for in instancia.split() if not in in stopwords]\n",
    "    return (' '.join(palavras))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5faec4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplica a função em todos os dados:\n",
    "tweets = [Preprocessing(i) for i in df.tweet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6a4828",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eaa543d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['preprocessed'] = tweets\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0a59d1",
   "metadata": {},
   "source": [
    "# Remover os caracteress indesejados e stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240d2b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "def prep_tweets(tweet):\n",
    "    \n",
    "    tweet = BeautifulSoup(tweet, 'html.parser').get_text() # Remove HTML Tags\n",
    "    tweet = re.sub(r\"[^a-zA-Zà-úÀ-Ú0-9]\", \" \", tweet.lower()) # Converte para minusculo\n",
    "    #words = tweet_tokenizer.tokenize(text) \n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16884db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888ce03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_tweets'] = [prep_tweets(tweet) for tweet in df.preprocessed]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66a456b",
   "metadata": {},
   "source": [
    "# Contar quantidade  de palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4784cb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import CountVectorizer para contar o numero de vezes que uma palavra ocorre\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afe36e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057bb213",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
